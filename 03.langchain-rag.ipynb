{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4cbf39-05b0-44d8-81a5-8adc4fd5ac41",
   "metadata": {},
   "source": [
    "## 构建一个RAG应用\n",
    "> RAG：Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e475e-b8c3-4f39-a3ce-e85082dd87a1",
   "metadata": {},
   "source": [
    "**官方文档：** https://python.langchain.com/docs/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a5ef5-4af4-44fb-93f6-5c1135f75e9e",
   "metadata": {},
   "source": [
    "构建一个RAG简单应用主要包含两部分：文档索引和查询生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb1f4b7-3138-42c9-ad43-b1d0c646533e",
   "metadata": {},
   "source": [
    "### 第一部分：文档索引\n",
    "\n",
    "#### 参考文档\n",
    "1. https://python.langchain.com/docs/tutorials/retrievers/\n",
    "\n",
    "#### 核心步骤\n",
    "1. 加载原始数据（非结构化的文本数据）\n",
    "2. 切分文本数据\n",
    "3. 存储处理后的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e7944-47f4-426d-a556-b48838047071",
   "metadata": {},
   "source": [
    "#### 第一步：加载原始数据\n",
    "数据来源CSV文件，其它类型的数据加载可以参考文档：https://python.langchain.com/docs/how_to/#document-loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18410bdd-aa3b-4a83-9fc9-9eaf0aa42118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 相对路径\n",
    "csv_file_path = \"./knowledge-documents.csv\"\n",
    "loader = CSVLoader(\n",
    "    file_path=csv_file_path,\n",
    "    content_columns=[\"知识项\"],\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"',\n",
    "        # \"fieldnames\": [\"知识项\"]\n",
    "    }\n",
    ")\n",
    "content = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5742eedb-c1ce-40a8-91b9-e22c8621f047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './knowledge-documents.csv', 'row': 0}, page_content='知识项: 为了验证CodeAct的有效性，本文进行了一系列实验，比较了CodeAct、JSON和文本格式在工具调用任务中的表现。实验结果表明，CodeAct在大多数LLM上表现优于或至少不逊色于JSON和文本格式。特别是在开源模型上，CodeAct的优势更为明显，因为开源模型在预训练阶段接触了大量的代码数据，使得它们更容易适应CodeAct的格式。'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='知识项: MCP（Model Context Protocol，模型上下文协议）是由 Anthropic 在 2024 年底推出的一种开放协议，旨在通过标准化接口实现大语言模型（LLM）与外部数据源及工具的无缝集成。我们可以这样理解 MCP，它就像是 AI 应用领域的 USB-C 接口。正如 USB-C 为各种设备提供了统一的连接方式，MCP 也为 AI 模型与不同数据源和工具之间提供了一种标准化的连接方式，这也极大地提高了用户的体验和效率。之所以发布 MCP，Anthropic 在一篇博客中表示随着 AI 助手越来越获得主流机构采用，行业在模型能力上投入巨大，推理和质量方面取得了快速进步。然而，即使是最复杂的模型也受到其与数据隔离的限制 —— 被困在信息孤岛和遗留系统中。每个新的数据源都需要自己的定制实现，使得真正连接的系统难以扩展。MCP 解决了这一挑战。它提供了一个通用的开放标准，用于将 AI 系统与数据源连接起来，用单一协议取代了分散的集成。结果是为 AI 系统提供了一种更简单、更可靠的方式，以获取它们所需的数据。'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='知识项: 第一罪(FP1)：内容缺失（Missing Content）。提问的问题，无法在被检索文档库中找到，最准确的答案是缺失的。理想情况下，RAG系统回应应该是“抱歉，我不知道答案”。然而，对于检索内容相关但没有相关答案的问题，系统可能被误导，给出一个respone。第二宗罪(FP2)：检索的TopK内容缺失(Missed the Top Ranked Documents)。问题的答案在文档库中，但排名得分不够高，无法返回给用户。理论上，检索过程中所有文档都会被排名得分。然而，在实际操作中，会返回排名前K个文档，为了提高召回率，K不可能设置的无限大，必须基于LLM大模型的能力，折中选择的一个值。第三宗罪(FP3)：未在上下文中（Not in Context） - 整合策略局限性。从数据库中检索到了包含答案的文档，但在生成答案的过程中，这些文档并未被纳入上下文。当数据库返回许多文档时，会进行整合过程以获取答案，此时会发生这种情况。第四宗罪(FP4)：未提取（Not Extracted）答案存在于上下文中，但大型语言模型未能提取出正确的答案。通常，这是因为上下文中存在太多噪声或矛盾信息。简而言之，Retrival命名是对的，但是LLM根据Retrival回答问题出错。睁眼说瞎话的概率明显大于用户可以接受的概率（用户一般只能接收0.1%的错误概率）第五宗罪(FP5)：错误格式(Wrong Format)。问题涉及以某种格式（如表格或列表）提取信息，而大型语言模型忽略了这一指示。第六宗罪(FP6)：错误的特异性(Incorrect Specificity)。返回的答案包含在响应中，但不够具体或过于具体，无法满足用户需求。这种情况发生在RAG系统设计者对某个问题有期望的结果，例如教师对学生。在这种情况下，应该提供具体的教育内容和答案，而不仅仅是答案。当用户不确定如何提问并过于笼统时，也会出现特异性错误。第七宗罪(FP7)：不完整（Incomplete）。不完整的答案并非错误，但缺少一些信息，尽管这些信息存在于上下文中并可供提取。')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e4b6e-244c-490e-a869-b4269a798505",
   "metadata": {},
   "source": [
    "#### 第二步：切分文本数据\n",
    "RecursiveCharacterTextSplitter做了什么？为什么要做文本分割？\n",
    "TextSplitter是做文本数据的分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f260208-d68c-4f38-871d-8de6884928dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "doc_splits = text_splitter.split_documents(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92308a83-2e14-499d-aa73-482ba03cebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './knowledge-documents.csv', 'row': 0}, page_content='知识项:'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 0}, page_content='为了验证CodeAct的有效性，本文进行了一系列实验，比较了CodeAct、JSON和文本格式在工具调用任务中的表现。实验结果表明，CodeAct在大多数LLM上表现优于或至少不逊色于JSON和文本'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 0}, page_content='M上表现优于或至少不逊色于JSON和文本格式。特别是在开源模型上，CodeAct的优势更为明显，因为开源模型在预训练阶段接触了大量的代码数据，使得它们更容易适应CodeAct的格式。'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='知识项: MCP（Model Context Protocol，模型上下文协议）是由 Anthropic 在 2024'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='Anthropic 在 2024 年底推出的一种开放协议，旨在通过标准化接口实现大语言模型（LLM）与外部数据源及工具的无缝集成。我们可以这样理解 MCP，它就像是 AI 应用领域的 USB-C'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='AI 应用领域的 USB-C 接口。正如 USB-C 为各种设备提供了统一的连接方式，MCP 也为 AI'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='也为 AI 模型与不同数据源和工具之间提供了一种标准化的连接方式，这也极大地提高了用户的体验和效率。之所以发布 MCP，Anthropic 在一篇博客中表示随着 AI'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='在一篇博客中表示随着 AI 助手越来越获得主流机构采用，行业在模型能力上投入巨大，推理和质量方面取得了快速进步。然而，即使是最复杂的模型也受到其与数据隔离的限制 ——'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='—— 被困在信息孤岛和遗留系统中。每个新的数据源都需要自己的定制实现，使得真正连接的系统难以扩展。MCP 解决了这一挑战。它提供了一个通用的开放标准，用于将 AI'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 1}, page_content='AI 系统与数据源连接起来，用单一协议取代了分散的集成。结果是为 AI 系统提供了一种更简单、更可靠的方式，以获取它们所需的数据。'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='知识项: 第一罪(FP1)：内容缺失（Missing'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='Content）。提问的问题，无法在被检索文档库中找到，最准确的答案是缺失的。理想情况下，RAG系统回应应该是“抱歉，我不知道答案”。然而，对于检索内容相关但没有相关答案的问题，系统可能被误导，给出'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='没有相关答案的问题，系统可能被误导，给出一个respone。第二宗罪(FP2)：检索的TopK内容缺失(Missed'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='the Top Ranked'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='Documents)。问题的答案在文档库中，但排名得分不够高，无法返回给用户。理论上，检索过程中所有文档都会被排名得分。然而，在实际操作中，会返回排名前K个文档，为了提高召回率，K不可能设置的无限大'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='档，为了提高召回率，K不可能设置的无限大，必须基于LLM大模型的能力，折中选择的一个值。第三宗罪(FP3)：未在上下文中（Not'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='in Context） -'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='整合策略局限性。从数据库中检索到了包含答案的文档，但在生成答案的过程中，这些文档并未被纳入上下文。当数据库返回许多文档时，会进行整合过程以获取答案，此时会发生这种情况。第四宗罪(FP4)：未提取（N'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='这种情况。第四宗罪(FP4)：未提取（Not'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='Extracted）答案存在于上下文中，但大型语言模型未能提取出正确的答案。通常，这是因为上下文中存在太多噪声或矛盾信息。简而言之，Retrival命名是对的，但是LLM根据Retrival回答问题'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='，但是LLM根据Retrival回答问题出错。睁眼说瞎话的概率明显大于用户可以接受的概率（用户一般只能接收0.1%的错误概率）第五宗罪(FP5)：错误格式(Wrong'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='Format)。问题涉及以某种格式（如表格或列表）提取信息，而大型语言模型忽略了这一指示。第六宗罪(FP6)：错误的特异性(Incorrect'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='Specificity)。返回的答案包含在响应中，但不够具体或过于具体，无法满足用户需求。这种情况发生在RAG系统设计者对某个问题有期望的结果，例如教师对学生。在这种情况下，应该提供具体的教育内容和'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='。在这种情况下，应该提供具体的教育内容和答案，而不仅仅是答案。当用户不确定如何提问并过于笼统时，也会出现特异性错误。第七宗罪(FP7)：不完整（Incomplete）。不完整的答案并非错误，但缺少一些'),\n",
       " Document(metadata={'source': './knowledge-documents.csv', 'row': 2}, page_content='te）。不完整的答案并非错误，但缺少一些信息，尽管这些信息存在于上下文中并可供提取。')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b1a50-be66-49da-b4bc-7a4517ff7896",
   "metadata": {},
   "source": [
    "#### 第三步：存储处理后的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9383ee-7a88-4204-8a25-803627ce7942",
   "metadata": {},
   "source": [
    "### 第二部分：查询生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14ddb4-f69c-4f93-b324-6dbc9c587bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
