"知识项"
"为了验证CodeAct的有效性，本文进行了一系列实验，比较了CodeAct、JSON和文本格式在工具调用任务中的表现。实验结果表明，CodeAct在大多数LLM上表现优于或至少不逊色于JSON和文本格式。特别是在开源模型上，CodeAct的优势更为明显，因为开源模型在预训练阶段接触了大量的代码数据，使得它们更容易适应CodeAct的格式。"
"MCP（Model Context Protocol，模型上下文协议）是由 Anthropic 在 2024 年底推出的一种开放协议，旨在通过标准化接口实现大语言模型（LLM）与外部数据源及工具的无缝集成。我们可以这样理解 MCP，它就像是 AI 应用领域的 USB-C 接口。正如 USB-C 为各种设备提供了统一的连接方式，MCP 也为 AI 模型与不同数据源和工具之间提供了一种标准化的连接方式，这也极大地提高了用户的体验和效率。之所以发布 MCP，Anthropic 在一篇博客中表示随着 AI 助手越来越获得主流机构采用，行业在模型能力上投入巨大，推理和质量方面取得了快速进步。然而，即使是最复杂的模型也受到其与数据隔离的限制 —— 被困在信息孤岛和遗留系统中。每个新的数据源都需要自己的定制实现，使得真正连接的系统难以扩展。MCP 解决了这一挑战。它提供了一个通用的开放标准，用于将 AI 系统与数据源连接起来，用单一协议取代了分散的集成。结果是为 AI 系统提供了一种更简单、更可靠的方式，以获取它们所需的数据。"
"第一罪(FP1)：内容缺失（Missing Content）。提问的问题，无法在被检索文档库中找到，最准确的答案是缺失的。理想情况下，RAG系统回应应该是“抱歉，我不知道答案”。然而，对于检索内容相关但没有相关答案的问题，系统可能被误导，给出一个respone。第二宗罪(FP2)：检索的TopK内容缺失(Missed the Top Ranked Documents)。问题的答案在文档库中，但排名得分不够高，无法返回给用户。理论上，检索过程中所有文档都会被排名得分。然而，在实际操作中，会返回排名前K个文档，为了提高召回率，K不可能设置的无限大，必须基于LLM大模型的能力，折中选择的一个值。第三宗罪(FP3)：未在上下文中（Not in Context） - 整合策略局限性。从数据库中检索到了包含答案的文档，但在生成答案的过程中，这些文档并未被纳入上下文。当数据库返回许多文档时，会进行整合过程以获取答案，此时会发生这种情况。第四宗罪(FP4)：未提取（Not Extracted）答案存在于上下文中，但大型语言模型未能提取出正确的答案。通常，这是因为上下文中存在太多噪声或矛盾信息。简而言之，Retrival命名是对的，但是LLM根据Retrival回答问题出错。睁眼说瞎话的概率明显大于用户可以接受的概率（用户一般只能接收0.1%的错误概率）第五宗罪(FP5)：错误格式(Wrong Format)。问题涉及以某种格式（如表格或列表）提取信息，而大型语言模型忽略了这一指示。第六宗罪(FP6)：错误的特异性(Incorrect Specificity)。返回的答案包含在响应中，但不够具体或过于具体，无法满足用户需求。这种情况发生在RAG系统设计者对某个问题有期望的结果，例如教师对学生。在这种情况下，应该提供具体的教育内容和答案，而不仅仅是答案。当用户不确定如何提问并过于笼统时，也会出现特异性错误。第七宗罪(FP7)：不完整（Incomplete）。不完整的答案并非错误，但缺少一些信息，尽管这些信息存在于上下文中并可供提取。"